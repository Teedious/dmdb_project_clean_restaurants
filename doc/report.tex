\documentclass[conference]{IEEEtran}
%\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{microtype}
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{csquotes}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[style=ieee]{biblatex}
\usepackage{pgfplots}
\usepackage{subcaption}
\usepackage{environ}
\usepackage{hyperref}
\bibliography{bibfile}

\pgfplotsset{width=\textwidth,compat=1.14}\usepgfplotslibrary{statistics}

%\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\makeatletter
\pgfplotsset{
    boxplot/hide outliers/.code={
        \def\pgfplotsplothandlerboxplot@outlier{}%
    }
}
\makeatother
\begin{document}

\title{Cleaning and Visualizing a dirty set of restaurant data}


\author{\IEEEauthorblockN{Florian Loher}
\IEEEauthorblockA{\textit{Technical University of Applied
Science Regensburg} \\
florian.loher@st.oth-regensburg.de}
%\and
}

\maketitle

\begin{abstract}
This document shows a possible approach to cleaning and visualizing the dirty dataset provided at \url{https://hpi.de/naumann/projects/repeatability/datasets/restaurants-dataset.html}. It describes how the data is first audited, then cleaned in MongoDB, removing duplicates, using a common search engine to find correct restaurant names and standardizing road and city names. Lastly the data is visualized by generating a website that contains an OSM map and markers indicating the location of each restaurant.
\end{abstract}

\begin{IEEEkeywords}
MongoDB, Data cleaning
\end{IEEEkeywords}

\section{Introduction}
Big data is a rapidly growing field of research that already gained overwhelming interest in the general public. The amount of data is increasing at an exponential rate an is likely to grow further at this rate. To be able to leverage the power of data, the need for ways to clean is as high as ever.

Data cleaning, also referred to as data scrubbing or data cleansing, is a research field concerned with improving the quality of faulty data. Typical aspects that are sought to be improved are the amount of duplicates, type errors or inconsistencies\cite{Bilenko.2003}.

In this article I am going to outline a possible approach to detecting duplicates in a dataset of 864 
restaurants\footnote{Restaurant data provided at \url{https://hpi.de/fileadmin/user_upload/fachgebiete/naumann/projekte/repeatability/Restaurants/restaurants.tsv}}.
I first audit the data. Then  I generate a training set, standardize fields and choose \emph{SoftTF-IDF} string matching measure with \emph{Jaro-Distance} as sub measure as the algorithm for duplicate detection. After creating a gold standard for the training set I train the thresholds for restaurant name, phone number and address similarity that determine if two records will be declared duplicates. Lastly the detection algorithm is run on the test data and compared to the gold 
standard\footnote{Gold standard provided at \url{https://hpi.de/fileadmin/user_upload/fachgebiete/naumann/projekte/repeatability/Restaurants/restaurants_DPL.tsv}}.
Using and comparing different sizes of training data I show that even with a training set $10\%$  the size of the test data (86 records, 22 of which are part of duplicates) a recall of $\approx86\%$ is with a precision of $\approx95\%$ typically achieved.

In section \ref{basics} I am going to introduce basic terminology concerning data cleaning and describe the string-matching algorithms I use. Section 
%% Outline
\section{Basics}\label{basics}
\subsection{Duplicate Detection Fundamentals}
\subsection{String matching}
Duplicate detection relies on the matching of strings i.e.\ comparing fields of distinct records in a given dataset and calculating how similar they are, based on a defined measure.

Token-based measures are typically optimized to handle rotation errors. Frequent differences between fields that represent the same entity are for example swapping first and last name, or having a title prepended or put at the end. By splitting the strings into tokens and comparing the resulting sets of tokens such rotations cease to impact those measures. The token-based string matching algorithm \emph{SoftTF-IDF} (soft term frequency, indirect document frequency) 
\subsection{Matching algorithms for names and addresses}

\section{Auditing and data preparation}\label{prep}
Before trying to find duplicate data in any given dataset most data cleaning approaches start with a phase of auditing and preparing the data. This includes but is not limited to discovering which types of fields are present in the data and removing unnecessary characters from fields.

\section{Generation of training data}\label{train_gen}

\section{Choice of string-matching algorithm SoftTF-IDF}\label{matching}

\section{Training with training data}\label{training}

\section{Detection of duplicates in restaurant data}\label{duplicate_detection}

\section{Comparison of different sizes of training data}\label{comparison}

\section{Conclusions}
\begin{figure*}
	\begin{subfigure}[t]{\textwidth}
		\begin{tikzpicture}
			\begin{axis}
			[
				height = 6cm,
				xmin = 0.65,
				xmax = 1.01,
				xlabel = recall,
				ylabel = training data size (\%),
				ytick = {1,2,3,4,5,6,7,8,9,10},
				yticklabels = {10,20,30,40,50,60,70,80,90,100},
				boxplot/draw direction=x
			]
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_1.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_2.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_3.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_4.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_5.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_6.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_7.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_8.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_9.txt};
				\addplot [boxplot] table [y=training_data_recall, col sep=comma] {../data/results/precision_recall_10.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Recall of training data with different sizes of training data and optimal thresholds}
	\end{subfigure}
	\begin{subfigure}[t]{\textwidth}
		\begin{tikzpicture}
			\begin{axis}
			[
				height = 6cm,
				xmin = 0.65,
				xmax = 1.01,
				xlabel = recall,
				ylabel = training data size (\%),
				ytick = {1,2,3,4,5,6,7,8,9,10},
				yticklabels = {10,20,30,40,50,60,70,80,90,100},
				boxplot/draw direction=x
			]
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_1.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_2.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_3.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_4.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_5.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_6.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_7.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_8.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_9.txt};
				\addplot [boxplot] table [y=test_data_recall, col sep=comma] {../data/results/precision_recall_10.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Recall of test data with different sizes of training data and optimal thresholds}
	\end{subfigure}
\end{figure*}

\begin{figure*}
	\begin{subfigure}{\textwidth}
		\begin{tikzpicture}
			\begin{axis}
			[
				height=6cm,
				xmin = 0.65,
				xmax = 1.01,
				xlabel = precision,
				ylabel = training data size (\%),
				ytick = {1,2,3,4,5,6,7,8,9,10},
				yticklabels = {10,20,30,40,50,60,70,80,90,100},
				boxplot/draw direction=x
			]
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_1.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_2.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_3.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_4.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_5.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_6.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_7.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_8.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_9.txt};
				\addplot [boxplot] table [y=training_data_precision, col sep=comma] {../data/results/precision_recall_10.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Precision of training data with different sizes of training data and optimal thresholds}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\begin{tikzpicture}
			\begin{axis}
			[
				height=6cm,
				xmin = 0.65,
				xmax = 1.01,
				xlabel = precision,
				ylabel = training data size (\%),
				ytick = {1,2,3,4,5,6,7,8,9,10},
				yticklabels = {10,20,30,40,50,60,70,80,90,100},
				boxplot/draw direction=x
			]
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_1.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_2.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_3.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_4.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_5.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_6.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_7.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_8.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_9.txt};
				\addplot [boxplot] table [y=test_data_precision, col sep=comma] {../data/results/precision_recall_10.txt};
			\end{axis}
		\end{tikzpicture}
		\caption{Precision of test data with different sizes of training data and optimal thresholds}
	\end{subfigure}
		
\end{figure*}

\begin{figure}
	\begin{tikzpicture}
		\begin{axis}
		[
			legend pos=north west,
			height=6cm,
			width=7cm,
		]
			\addplot+  table [x=x,y=phone_threshold, col sep=comma] {../data/results/summary.txt};
			\addlegendentry{phone}
			\addplot+  table [x=x,y=name_threshold, col sep=comma] {../data/results/summary.txt};
			\addlegendentry{name}
			\addplot+  table [x=x,y=address_threshold, col sep=comma] {../data/results/summary.txt};
			\addlegendentry{address}
		\end{axis}
	\end{tikzpicture}
\end{figure}

\printbibliography

\end{document}